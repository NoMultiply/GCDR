{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f31cfebf",
   "metadata": {},
   "source": [
    "# Data Processer\n",
    "\n",
    "## Data Source:\n",
    "* Yelp: https://www.yelp.com/dataset/\n",
    "* Amazon-Books: https://jmcauley.ucsd.edu/data/amazon/\n",
    "* MovieLens: https://grouplens.org/datasets/movielens/1m/\n",
    "* KuaiRec: https://kuairec.com/\n",
    "\n",
    "## Directories Tree\n",
    "```bash\n",
    "raw\n",
    "├── books\n",
    "│   ├── Books.jsonl\n",
    "│   └── meta_Books.jsonl\n",
    "├── kuairec\n",
    "│   └── data\n",
    "│       ├── big_matrix.csv\n",
    "│       ├── item_categories.csv\n",
    "│       └── small_matrix.csv\n",
    "├── movielens\n",
    "│   ├── movies.dat\n",
    "│   └── ratings.dat\n",
    "└── yelp\n",
    "    ├── yelp_academic_dataset_business.json\n",
    "    └── yelp_academic_dataset_review.json\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8207a654",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "valid_rate, test_rate = 0.1, 0.2\n",
    "\n",
    "def tqdm_(data_iter, **kwargs):\n",
    "    return tqdm(data_iter, bar_format='{l_bar}{r_bar}', **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d10440d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc_categories(items, all_categories, k=100):\n",
    "    category_set = set(x[0] for x in sorted(all_categories.items(), key=lambda x: x[1], reverse=True)[:k])\n",
    "    trunc_items = {}\n",
    "    for iid, categories in tqdm_(items.items()):\n",
    "        cs = category_set.intersection(categories)\n",
    "        if len(cs) == 0:\n",
    "            continue\n",
    "        trunc_items[iid] = cs\n",
    "    return trunc_items, category_set\n",
    "\n",
    "def get_split_nums(n):\n",
    "    n_valid = round(n * valid_rate)\n",
    "    n_test = round(n * test_rate)\n",
    "    n_train = n - n_valid - n_test\n",
    "    return n_train, n_valid, n_test\n",
    "\n",
    "def _write(out, uid, iids, train_iids):\n",
    "    iids = [x for x in iids if x in train_iids]\n",
    "    if len(iids) == 0:\n",
    "        return 1\n",
    "    out.write(f'{uid}\\t{\",\".join(map(lambda x: str(train_iids[x]), iids))}\\n')\n",
    "    return 0\n",
    "\n",
    "\n",
    "def split_write(root, items, data, min_len=None):\n",
    "    train_iids = {}\n",
    "    trunc_data = {}\n",
    "    for uid, iids in tqdm_(data.items(), desc='[trunc_data]'):\n",
    "        iids = [x[0] for x in sorted(iids.items(), key=lambda x: x[1]) if x[0] in items]\n",
    "        n_train, n_valid, n_test = get_split_nums(len(iids))\n",
    "        if min(n_train, n_valid, n_test) <= 0:\n",
    "            continue\n",
    "        if min_len is not None and len(iids) < min_len:\n",
    "            continue\n",
    "        trunc_data[uid] = iids\n",
    "        for iid in iids[:n_train]:\n",
    "            train_iids[iid] = train_iids.get(iid, len(train_iids))\n",
    "    \n",
    "    print('# of trunc_data:', len(trunc_data))\n",
    "    print('# of train_iids:', len(train_iids))\n",
    "    \n",
    "    with open(os.path.join(root, 'item_categories.txt'), 'w', encoding='utf8') as out:\n",
    "        for iid in tqdm_(train_iids, desc='[item_categories]'):\n",
    "            out.write(f'{train_iids[iid]}\\t{\"|\".join(items[iid])}\\n')\n",
    "\n",
    "    n_user, n_interactions, n_not_so_good = 0, 0, 0\n",
    "    with open(os.path.join(root, 'train.txt'), 'w', encoding='utf8') as out_train:\n",
    "        with open(os.path.join(root, 'valid.txt'), 'w', encoding='utf8') as out_valid:\n",
    "            with open(os.path.join(root, 'test.txt'), 'w', encoding='utf8') as out_test:\n",
    "                for uid, iids in tqdm_(trunc_data.items(), desc='[train_valid_test]'):\n",
    "                    n_train, n_valid, n_test = get_split_nums(len(iids))\n",
    "                    assert min(n_train, n_valid, n_test) > 0\n",
    "                    n_interactions += len([x for x in iids if x in train_iids])\n",
    "                    n_not_so_good += _write(out_train, n_user, iids[:n_train], train_iids)\n",
    "                    n_not_so_good += _write(out_valid, n_user, iids[n_train:-n_test], train_iids)\n",
    "                    n_not_so_good += _write(out_test, n_user, iids[-n_test:], train_iids)\n",
    "                    n_user += 1\n",
    "\n",
    "    print(f'[{root}]')\n",
    "    print(f'# of users: {n_user}')\n",
    "    print(f'# of items: {len(train_iids)}')\n",
    "    print(f'# of interactions: {n_interactions}')\n",
    "    print(f'n_not_so_good: {n_not_so_good}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b01d6b7",
   "metadata": {},
   "source": [
    "# Yelp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c8b104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_root = 'raw/yelp'\n",
    "root = 'data/yelp'\n",
    "os.makedirs(root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7037273e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|| 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|| 150346/? [00:01<00:00, 97810.91it/s] \n"
     ]
    }
   ],
   "source": [
    "items = {}\n",
    "all_categories = {}\n",
    "with open(os.path.join(raw_root, 'yelp_academic_dataset_business.json'), encoding='utf8') as fin:\n",
    "    for line in tqdm_(fin):\n",
    "        item = json.loads(line)\n",
    "        if item['categories'] is None:\n",
    "            continue\n",
    "        categories = set(map(str.strip, item['categories'].split(',')))\n",
    "        for c in categories:\n",
    "            all_categories[c] = all_categories.get(c, 0) + 1\n",
    "        items[item['business_id']] = categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e96c5821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|| 6990280/? [01:15<00:00, 92658.09it/s]\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "with open(os.path.join(raw_root, 'yelp_academic_dataset_review.json'), encoding='utf8') as fin:\n",
    "    for line in tqdm_(fin):\n",
    "        edge = json.loads(line)\n",
    "        uid, iid, rating, t = edge['user_id'], edge['business_id'], edge['stars'], datetime.datetime.strptime(edge['date'], '%Y-%m-%d %H:%M:%S').timestamp()\n",
    "        if rating >= 4:\n",
    "            if uid not in data:\n",
    "                data[uid] = {}\n",
    "            data[uid][iid] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95d3a7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 150243/150243 [00:00<00:00, 465232.12it/s]\n"
     ]
    }
   ],
   "source": [
    "trunc_items, category_set = trunc_categories(items, all_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad6bb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[trunc_data]: 100%|| 1464850/1464850 [00:04<00:00, 335780.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trunc_data: 146949\n",
      "# of train_iids: 125879\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[item_categories]: 100%|| 125879/125879 [00:00<00:00, 591608.83it/s]\n",
      "[train_valid_test]: 100%|| 146949/146949 [00:01<00:00, 74786.49it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data/yelp]\n",
      "# of users: 146949\n",
      "# of items: 125879\n",
      "# of interactions: 2397886\n",
      "n_not_so_good: 4624\n"
     ]
    }
   ],
   "source": [
    "split_write(root, trunc_items, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ad7e3",
   "metadata": {},
   "source": [
    "# Amazon-Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49507ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_root = 'raw/books'\n",
    "root = 'data/books'\n",
    "os.makedirs(root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "728822d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|| 29475453/? [02:10<00:00, 225898.44it/s]\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "with open(os.path.join(raw_root, 'Books.jsonl'), encoding='utf8') as fin:\n",
    "    for line in tqdm_(fin):\n",
    "        d = json.loads(line)\n",
    "        uid, iid, rating, t = d['user_id'], d['parent_asin'], d['rating'], d['timestamp']\n",
    "        if rating >= 4:\n",
    "            if uid not in data:\n",
    "                data[uid] = {}\n",
    "            data[uid][iid] = t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5182b94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "|| 4448181/? [01:10<00:00, 62672.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3919508 2723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "items = {}\n",
    "all_categories = {}\n",
    "with open(os.path.join(raw_root, 'meta_Books.jsonl'), encoding='utf8') as fin:\n",
    "    for line in tqdm_(fin):\n",
    "        d = json.loads(line)\n",
    "        iid = d['parent_asin']\n",
    "        categories = d['categories']\n",
    "        if len(categories) == 0:\n",
    "            continue\n",
    "        items[iid] = set(categories)\n",
    "        for c in categories:\n",
    "            all_categories[c] = all_categories.get(c, 0) + 1\n",
    "print(len(items), len(all_categories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "accdfe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 3919508/3919508 [00:07<00:00, 500583.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3917787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trunc_items, category_set = trunc_categories(items, all_categories)\n",
    "print(len(trunc_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4dea4d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[trunc_data]: 100%|| 9244317/9244317 [00:37<00:00, 247157.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trunc_data: 712802\n",
      "# of train_iids: 1874004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[item_categories]: 100%|| 1874004/1874004 [00:03<00:00, 540980.94it/s]\n",
      "[train_valid_test]: 100%|| 712802/712802 [00:09<00:00, 78764.01it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data/books]\n",
      "# of users: 712802\n",
      "# of items: 1874004\n",
      "# of interactions: 9838152\n",
      "n_not_so_good: 165223\n"
     ]
    }
   ],
   "source": [
    "split_write(root, trunc_items, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39180f7",
   "metadata": {},
   "source": [
    "# MovieLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d52954a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_root = 'raw/movielens'\n",
    "root = 'data/movielens'\n",
    "os.makedirs(root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e35e9406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[movies.dat]: || 3883/? [00:00<00:00, 233287.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3883 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "items = {}\n",
    "all_categories = {}\n",
    "\n",
    "with open(os.path.join(raw_root, 'movies.dat'), encoding='ISO-8859-1') as fin:\n",
    "    for line in tqdm_(fin, desc='[movies.dat]'):\n",
    "        iid, _, categories = line.strip().split('::')\n",
    "        if len(categories) == 0:\n",
    "            continue\n",
    "        categories = categories.split('|')\n",
    "        items[iid] = set(categories)\n",
    "        for c in categories:\n",
    "            all_categories[c] = all_categories.get(c, 0) + 1\n",
    "print(len(items), len(all_categories))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ad2a5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ratings.dat]: || 1000209/? [00:00<00:00, 1149570.84it/s]\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "with open(os.path.join(raw_root, 'ratings.dat')) as fin:\n",
    "    for line in tqdm_(fin, desc='[ratings.dat]'):\n",
    "        uid, iid, rating, t = line.strip().split('::')\n",
    "        rating = float(rating)\n",
    "        if rating >= 4:\n",
    "            if uid not in data:\n",
    "                data[uid] = {}\n",
    "            data[uid][iid] = int(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e973c8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[trunc_data]: 100%|| 6038/6038 [00:00<00:00, 29000.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of trunc_data: 6028\n",
      "# of train_iids: 3422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[item_categories]: 100%|| 3422/3422 [00:00<00:00, 891706.53it/s]\n",
      "[train_valid_test]: 100%|| 6028/6028 [00:00<00:00, 24131.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data/movielens]\n",
      "# of users: 6028\n",
      "# of items: 3422\n",
      "# of interactions: 575056\n",
      "n_not_so_good: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "split_write(root, items, data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a3193e",
   "metadata": {},
   "source": [
    "# KuaiRec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5ebd1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_root = 'raw/kuairec'\n",
    "root = 'data/kuairec'\n",
    "os.makedirs(root, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06b016de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[big_matrix.csv]: || 12530806/? [00:19<00:00, 651126.94it/s]\n"
     ]
    }
   ],
   "source": [
    "all_data = {}\n",
    "with open(os.path.join(raw_root, 'data/big_matrix.csv')) as fin:\n",
    "    fin.readline()\n",
    "    for line in tqdm_(fin, desc='[big_matrix.csv]'):\n",
    "        user_id, video_id, play_duration, video_duration, time, date, timestamp, watch_ratio = line.strip().split(',')\n",
    "        watch_ratio = float(watch_ratio)\n",
    "        timestamp = float(timestamp)\n",
    "        if user_id not in all_data:\n",
    "            all_data[user_id] = {}\n",
    "        all_data[user_id][video_id] = (timestamp, all_data[user_id].get(video_id, (0, 0))[1] + watch_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf69d884",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[train_data]:   0%|| 0/7176 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[train_data]: 100%|| 7176/7176 [00:01<00:00, 4307.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of train_idis: 10722\n",
      "# of train_data: 7176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = {}\n",
    "train_iids = {}\n",
    "for uid in tqdm_(all_data, desc='[train_data]'):\n",
    "    d = []\n",
    "    for iid in all_data[uid]:\n",
    "        if all_data[uid][iid][1] >= 2.0:\n",
    "            d.append((iid, all_data[uid][iid][0]))\n",
    "            train_iids[iid] = train_iids.get(iid, len(train_iids))\n",
    "    if len(d) > 0:\n",
    "        train_data[uid] = d\n",
    "\n",
    "print(f'# of train_idis: {len(train_iids)}')\n",
    "print(f'# of train_data: {len(train_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e9b60fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[small_matrix.csv]: || 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[small_matrix.csv]: || 4676570/? [00:05<00:00, 801536.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_skip_uid: 0\n",
      "n_skip_iid: 7613\n",
      "n_skip_timestamp: 7613\n",
      "n_skip_wr: 4459341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_data = {}\n",
    "n_skip_uid, n_skip_iid, n_skip_timestamp, n_skip_wr = 0, 0, 0, 0\n",
    "\n",
    "with open(os.path.join(raw_root, 'data/small_matrix.csv')) as fin:\n",
    "    fin.readline()\n",
    "    for line in tqdm_(fin, desc='[small_matrix.csv]'):\n",
    "        user_id, video_id, play_duration, video_duration, time, date, timestamp, watch_ratio = line.strip().split(',')\n",
    "        watch_ratio = float(watch_ratio)\n",
    "        if user_id not in train_data:\n",
    "            n_skip_iid += 1\n",
    "            continue\n",
    "        if video_id not in train_iids:\n",
    "            n_skip_iid += 1\n",
    "            continue\n",
    "        if watch_ratio < 2.0:\n",
    "            n_skip_wr += 1\n",
    "            continue\n",
    "        if timestamp == '':\n",
    "            n_skip_timestamp += 1\n",
    "            continue\n",
    "        assert video_id not in all_data[user_id]\n",
    "        if user_id not in test_data:\n",
    "            test_data[user_id] = []\n",
    "        test_data[user_id].append((video_id, float(timestamp)))\n",
    "\n",
    "print('n_skip_uid:', n_skip_uid)\n",
    "print('n_skip_iid:', n_skip_timestamp)\n",
    "print('n_skip_timestamp:', n_skip_timestamp)\n",
    "print('n_skip_wr:', n_skip_wr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7addb64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[item_categories.csv]: || 0/? [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[item_categories.csv]: || 10728/? [00:00<00:00, 165742.10it/s]\n",
      "[item_categories.txt]: 100%|| 10722/10722 [00:00<00:00, 974607.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of all_categories: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "items = {}\n",
    "all_categories = {}\n",
    "with open(os.path.join(raw_root, 'data/item_categories.csv')) as fin:\n",
    "    fin.readline()\n",
    "    for line in tqdm_(fin, desc='[item_categories.csv]'):\n",
    "        iid, feat = line.strip().split(',', 1)\n",
    "        if iid not in train_iids:\n",
    "            continue\n",
    "        feat = eval(feat.strip('\"'))\n",
    "        assert isinstance(feat, list)        \n",
    "        for c in feat:\n",
    "            all_categories[c] = all_categories.get(c, 0) + 1\n",
    "        assert iid not in items\n",
    "        items[iid] = feat\n",
    "\n",
    "with open(os.path.join(root, 'item_categories.txt'), 'w') as out:\n",
    "    for iid in tqdm_(items, desc='[item_categories.txt]'):\n",
    "        out.write(f'{iid}\\t{\"|\".join(map(str, items[iid]))}\\n')\n",
    "\n",
    "print('# of all_categories:', len(all_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ab9e3196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[splits]: 100%|| 7176/7176 [00:00<00:00, 22977.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[data/kuairec]\n",
      "# of users: 7176\n",
      "# of items: 10722\n",
      "# of interactions: 1514281\n",
      "n_not_so_good_1: 0\n",
      "n_not_so_good_2: 5765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "n_not_so_good_1 = 0\n",
    "n_not_so_good_2 = 0\n",
    "kuairec_valid_rate = 1 / 3\n",
    "n_interactions = 0\n",
    "with open(os.path.join(root, 'train.txt'), 'w') as out_train:\n",
    "    with open(os.path.join(root, 'valid.txt'), 'w') as out_valid:\n",
    "        with open(os.path.join(root, 'test.txt'), 'w') as out_test:\n",
    "            for uid in tqdm_(train_data, desc='[splits]'):\n",
    "                iids = [x[0] for x in sorted(train_data[uid], key=lambda x: x[1])]\n",
    "                out_train.write(f'{uid}\\t{\",\".join(iids)}\\n')\n",
    "                n_interactions += len(iids)\n",
    "\n",
    "                if uid in test_data:\n",
    "                    iids = [x[0] for x in sorted(test_data[uid], key=lambda x: x[1])]\n",
    "                    n_interactions += len(iids)\n",
    "                    n_valid = round(len(iids) * kuairec_valid_rate)\n",
    "                    n_test = len(iids) - n_valid\n",
    "                    if n_valid <= 0 or n_test <= 0:\n",
    "                        n_not_so_good_1 += 1\n",
    "                    else:\n",
    "                        out_valid.write(f'{uid}\\t{\",\".join(iids[:n_valid])}\\n')\n",
    "                        out_test.write(f'{uid}\\t{\",\".join(iids[n_valid:])}\\n')\n",
    "                else:\n",
    "                    n_not_so_good_2 += 1\n",
    "\n",
    "print(f'[{root}]')\n",
    "print(f'# of users: {len(train_data)}')\n",
    "print(f'# of items: {len(train_iids)}')\n",
    "print(f'# of interactions: {n_interactions}')\n",
    "print(f'n_not_so_good_1: {n_not_so_good_1}')\n",
    "print(f'n_not_so_good_2: {n_not_so_good_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f50050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
